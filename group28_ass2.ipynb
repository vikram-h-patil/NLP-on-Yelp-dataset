{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authors: \n",
    "- Vikram Hanumanthrao Patil\n",
    "- Prashantkumar Kulkarni\n",
    "\n",
    "##### Date: 2/6/2019\n",
    "\n",
    "##### Version: 3.0\n",
    "\n",
    "##### Environment: Python 3.6.1 and Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "### 1. [Importing libraries](#library)\n",
    "### 2. [Initialization](#initialisation)\n",
    "### 3. [Read training and label](#read_train)\n",
    "### 4. [Data pre-processing](#preprocess)   \n",
    "### 5. [Feature generation](#feature)\n",
    "- #### 5.1 [Dimention reduction technique(Chi-squared)](#dimension)\n",
    "- #### 5-2 [Multinomial logistic regression](#model)\n",
    "- #### 5-3 [Cross-validation](#cv)         \n",
    "\n",
    "### 6. [Predict on test data](#test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries <a name=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkul0001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pattern.en import parse\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "import swifter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization<a name=\"initialisation\"></a>\n",
    "\n",
    "### Creating a custom dictionary to expand all the decontract words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the lemmatizer.\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "# Creating a custom dictionary to expand all the decontract words\n",
    "appos = {\n",
    "\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\", \"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\", \"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \"shan't\" : \"shall not\", \"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\", \"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\", \"where's\" : \"where is\", \"who'd\" : \"who would\", \"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\", \"you'd\" : \"you would\", \"you'll\" : \"you will\",\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\",\"didn't\": \"did not\"\n",
    "}\n",
    "#reference[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading the training data and labels <a name=\"read_train\"></a>\n",
    "\n",
    "### merging both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_data.csv\", sep=',') # read training data\n",
    "data_labels = pd.read_csv(\"train_label.csv\", sep=',') # read training labels\n",
    "df=pd.merge(data,data_labels,on='trn_id',how='left') # merging both of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data pre-processing <a name=\"preprocess\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079f065be9c44aca8a0bb251c93b0f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=650000, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------\n",
    "# Data pre-processing step\n",
    "#--------------------------\n",
    "def pre_process(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. converts to lower\n",
    "    2. Splits the sentence into tokens\n",
    "    3. Decontract the words. For example: \"won't\" --> \"will not\"\n",
    "    4. Lemmatization, reduces words to their base word\n",
    "    5. Returns the sentence of the cleaned text\n",
    "    \"\"\"\n",
    "    text = \"\".join([word.lower() for word in text])\n",
    "    tokens = text.split(\" \")\n",
    "    tokens = [appos[word] if word in appos else word for word in tokens]\n",
    "    text = \" \".join([wn.lemmatize(word) for word in tokens])   \n",
    "    return text\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "# execute pre-processing\n",
    "#--------------------------\n",
    "df['text']=df.swifter.apply(lambda x:pre_process(x['text']),axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature generation <a name=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1- Dimension reduction technique (Chi-square)<a name=\"dimension\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#dimension reduction using chi-square\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(df['text'], df['label'], test_size=.02)\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=100000,ngram_range=(1, 3))\n",
    "x_train_tfidf = tvec.fit_transform(x_train)\n",
    "x_validation_tfidf = tvec.transform(x_validation)\n",
    "\n",
    "#reference[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2 Multinomial logistic regression<a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6501538461538462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = SelectKBest(chi2, k=40000)\n",
    "x_train_feature_selected=ch.fit_transform(x_train_tfidf, y_train)\n",
    "x_test_chi_selected = ch.transform(x_validation_tfidf)\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.LogisticRegression(multi_class='multinomial',solver = 'newton-cg')\n",
    "clf.fit(x_train_feature_selected, y_train)\n",
    "score = clf.score(x_test_chi_selected, y_validation)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3 Cross-validation <a name=\"cv\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=3)\n",
    "cross_val_score(clf, x_train_chi2_selected, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Prediction on test data<a name=\"test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "## Reading the test file into dataframe\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "test=pd.read_csv(\"test_data.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d736d47d1048bc915116008a04aba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=50000, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "## Cleaning the test data as per the cleaning technique of train data\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "test['text']=test.swifter.apply(lambda x:pre_process(x['text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------\n",
    "## Transforming the text into vector tfidf vectorizer with chi-sqaure\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "test_matrix=  tvec.transform(test['text'])\n",
    "test_matrix = ch.transform(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "## predicting the labels, storing it as label column in test dataframe\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "test['label'] = pd.DataFrame(clf.predict(test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id  label\n",
       "0  test_1      2\n",
       "1  test_2      4\n",
       "2  test_3      2\n",
       "3  test_4      5\n",
       "4  test_5      5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------------------------------------------------\n",
    "## dropping all other columns keeping only test_id and label\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "test=test[['test_id','label']]\n",
    "\n",
    "############################################################\n",
    "\n",
    "#--------------------------------\n",
    "#Converting the dataframe to csv\n",
    "#--------------------------------\n",
    "\n",
    "test.to_csv('predict_label.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".[1] https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view                       \n",
    "[2] https://github.com/tthustla/twitter_sentiment_analysis_part8/blob/master/Capstone_part4-Copy6.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
